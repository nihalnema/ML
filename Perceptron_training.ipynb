{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Output : \n",
      "\n",
      " Final weights w1, w2 are : \n",
      "[ 4.54275665 -7.14088886]\n",
      "\n",
      " Final bias is w0 is : \n",
      "-2.174588767300246\n",
      "\n",
      " Testing for IRIS Dataset \n",
      "\n",
      "input :  [5.5 2.3] ---> output :  1\n",
      "input :  [4.9 3.1] ---> output :  0\n",
      "input :  [5.5 2.5] ---> output :  1\n",
      "input :  [5.  3.4] ---> output :  0\n",
      "input :  [5.6 2.9] ---> output :  1\n",
      "input :  [5.  2.3] ---> output :  1\n",
      "input :  [5.  3.3] ---> output :  0\n",
      "input :  [5.1 3.5] ---> output :  0\n",
      "input :  [5.  3.4] ---> output :  0\n",
      "input :  [6.  2.7] ---> output :  1\n",
      "input :  [5.9 3.2] ---> output :  1\n",
      "input :  [4.8 3.4] ---> output :  0\n",
      "input :  [4.6 3.4] ---> output :  0\n",
      "input :  [6.  3.4] ---> output :  1\n",
      "input :  [6.3 3.3] ---> output :  1\n",
      "input :  [4.3 3. ] ---> output :  0\n",
      "input :  [5.1 3.3] ---> output :  0\n",
      "input :  [4.4 3. ] ---> output :  0\n",
      "input :  [5.5 3.5] ---> output :  0\n",
      "input :  [5.8 4. ] ---> output :  0\n",
      "input :  [5.3 3.7] ---> output :  0\n",
      "input :  [4.9 3.1] ---> output :  0\n",
      "input :  [6.1 2.8] ---> output :  1\n",
      "input :  [6.1 3. ] ---> output :  1\n",
      "input :  [5.4 3.9] ---> output :  0\n",
      "input :  [4.9 3. ] ---> output :  0\n",
      "input :  [6.7 3.1] ---> output :  1\n",
      "input :  [5.2 4.1] ---> output :  0\n",
      "input :  [6.  2.2] ---> output :  1\n",
      "input :  [6.8 2.8] ---> output :  1\n",
      "Expected Output  [1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
      "Predicted Output [1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Below code include perceptron training and testing on sample Iris dataset\n",
    "# here I have included all the explanation in code comments.\n",
    "# Output of the code can be seen below the code itself.\n",
    "# Further details is being explained in the next cell.\n",
    "\n",
    "# Importing numpy to operate with arrays & sklearn packages to load datasets\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "# Function to predict output based on its sign\n",
    "def signum(z):\n",
    "    if z<=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Function to train perceptron with learning_rate=alpha and epochs=100\n",
    "# @wt is weight matrix which is randomly assigned initially\n",
    "# @inputs is input matrix given to train perceptron\n",
    "# @target is expected output matrix\n",
    "\n",
    "def train_perceptron(inputs,target,wt):\n",
    "    alpha=0.1\n",
    "    epochs=100\n",
    "    # running loop for 100 epochs\n",
    "    for i in range(epochs):\n",
    "        # for each input vector calculate the output according to weights and bias\n",
    "        for j in range(inputs.shape[0]):\n",
    "            # calculating the predicted output\n",
    "            o=np.dot(inputs[j],wt[1:].T)\n",
    "            # adding the bias\n",
    "            o+=wt[0]\n",
    "            output=signum(o)\n",
    "            # modifying the weights after each iteration as per Stochastic Gradient Descent\n",
    "            wt[1:]+=alpha*(target[j]-output)*inputs[j]\n",
    "            #modifying the bias\n",
    "            wt[0]+=alpha*(target[j]-output)\n",
    "\n",
    "# list to store predicted output\n",
    "predictions=[]\n",
    "\n",
    "#function to predict output based on given weights,bias and input matrix\n",
    "def test_perceptron(wt,inputs):\n",
    "    for i in range(inputs.shape[0]):\n",
    "        z=np.dot(inputs[i],wt[1:].T)\n",
    "        z+=wt[0]\n",
    "        print(\"input : \",inputs[i],\"--->\", end=\" \")\n",
    "        print(\"output : \", signum(z))\n",
    "        predictions.append(signum(z))\n",
    "    \n",
    "    \n",
    "# main function from which execution begins    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print('\\n','Output : ')\n",
    "    \n",
    "    #loading the iris dataset\n",
    "    data=datasets.load_iris()\n",
    "    \n",
    "    #taking 100 samples from dataset with 2 features\n",
    "    #X stores input abd Y output\n",
    "    X=data.data[0:100,0:2]\n",
    "    Y=data.target[0:100]\n",
    "\n",
    "    #shuffling the data\n",
    "    m,n = X.shape\n",
    "    l= [i for  i in range(0, m)]\n",
    "    np.random.shuffle(l)\n",
    "    X=X[l]\n",
    "    Y=Y[l]\n",
    "    \n",
    "    #partitioning the dataset into training and testing\n",
    "    partition = (int)( 0.7 * m)\n",
    "    X_train = X[0:partition]\n",
    "    Y_train = Y[0:partition]\n",
    "    X_test  = X[partition:m]\n",
    "    Y_test  = Y[partition:m]\n",
    "\n",
    "    #assigning random weights and bias initially depending on number of features\n",
    "    wt=np.random.rand(X_train.shape[1]+1)\n",
    "    \n",
    "    #calling function to train our perceptron model\n",
    "    train_perceptron(X_train,Y_train,wt)\n",
    "\n",
    "    #printing final weights and bias after training the model\n",
    "    print('\\n','Final weights w1, w2 are : ')\n",
    "    print(wt[1:])\n",
    "    print('\\n','Final bias is w0 is : ')\n",
    "    print(wt[0])\n",
    "\n",
    "    #testing the model for sample inputs\n",
    "    print('\\n','Testing for IRIS Dataset', '\\n')\n",
    "    test_perceptron(wt,X_test)\n",
    "    Y_test=list(Y_test)\n",
    "    \n",
    "    #comparison of expected and predicted output\n",
    "    print('Expected Output ', Y_test)\n",
    "    print('Predicted Output', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Explanation :-\n",
    "    - The above code implements a model for perceptron learning algorithms.\n",
    "    - The sample dataset I have included is Iris which is available in sklearn package.\n",
    "    - Here I have used two features to predict output. And the sample data is being partitioned into\n",
    "      two sets one for training and other for testing.\n",
    "    - The function named 'train_perceptron' takes as argument weights,input_data, and target_data.\n",
    "      The values of epochs I have chosen is 100 and learning rate alpha to be 0.1\n",
    "      This function trains the model by updating weights after each iteration based on Stochastic \n",
    "      Gradient Descent.\n",
    "    - The function named 'test_perceptron' takes as argument the final weights,bias and test data &\n",
    "      Predict the output based on it.\n",
    "    - After the model is being created, we get the final weights stored in variable wt.\n",
    "    - The weight parameters and bias is now used to test the sample data. Which after testing is \n",
    "      being compared to expected output.\n",
    "    - Further things in code are self explanatory. \n",
    "'''      \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
